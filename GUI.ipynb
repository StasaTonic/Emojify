{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "caf4fe80",
   "metadata": {},
   "outputs": [],
   "source": [
    "#ucitavamo biblioteke\n",
    "import tkinter as tk\n",
    "from tkinter import *\n",
    "from PIL import Image\n",
    "from PIL import ImageTk\n",
    "import numpy as np\n",
    "import cv2\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import Dropout\n",
    "from tensorflow.keras.layers import Flatten\n",
    "from tensorflow.keras.layers import Conv2D\n",
    "from tensorflow.keras.layers import MaxPooling2D\n",
    "import os\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "import threading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d5594d90",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Pravimo istu arhitekturu kao i na treniranje modela, s tim da ovdje ne treniramo model, vec dodajemo one sacuvane weights\n",
    "face_model = Sequential()\n",
    "face_model.add(Conv2D(32, kernel_size=(3, 3), activation='relu', input_shape=(48,48,1)))\n",
    "face_model.add(Conv2D(64, kernel_size=(3, 3), activation='relu'))\n",
    "face_model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "face_model.add(Dropout(0.25))\n",
    "face_model.add(Conv2D(128, kernel_size=(3, 3), activation='relu'))\n",
    "face_model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "face_model.add(Conv2D(128, kernel_size=(3, 3), activation='relu'))\n",
    "face_model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "face_model.add(Dropout(0.25))\n",
    "face_model.add(Flatten())\n",
    "face_model.add(Dense(1024, activation='relu'))\n",
    "face_model.add(Dropout(0.5))\n",
    "face_model.add(Dense(7, activation='softmax'))\n",
    "\n",
    "# Load the saved weights\n",
    "face_model.load_weights('recognition_model.h5')\n",
    "\n",
    "# Ovo ne znam sta tacno radi, vidio sam da je upisano na nekim radovima :) \n",
    "cv2.ocl.setUseOpenCL(False)\n",
    "\n",
    "# Nazivi emocija \n",
    "\n",
    "emotion_dict = {0: \"   Angry   \", 1: \"Disgusted\", 2: \"  Fearful  \", 3: \"   Happy   \", 4: \"  Neutral  \", 5: \"    Sad   \", 6: \"Surprised\"}\n",
    "#ucitavamo slike emojija, ovi sa brojem 1 kao lice na mene(Ognjena), a sa brojem 2 na Stasu\n",
    "emoji_dist = {0:\"emojis/Angry1.png\", 1:\"emojis/Disgusted1.png\", 2:\"emojis/Fearful1.png\", 3:\"emojis/Happy1.png\", 4:\"emojis/Neutral1.png\", 5:\"emojis1/Sad1.png\", 6:\"emojis/Surprised1.png\"}\n",
    "#emoji_dist = {0:\"emojis/Angry2.png\", 1:\"emojis/Disgusted2.png\", 2:\"emojis/Fearful2.png\", 3:\"emojis/Happy2.png\", 4:\"emojis/Neutral2.png\", 5:\"emojis/Sad2.png\", 6:\"emojis/Surprised2.png\"}\n",
    "\n",
    "\n",
    "####################################\n",
    "# Procitajte prvo donji box jer je to glavni dio gui-a, ovo su funkcije koje se u njemu koriste \n",
    "\n",
    "\n",
    "# Global variables\n",
    "global last_frame1                                    \n",
    "last_frame1 = np.zeros((480, 640, 3), dtype=np.uint8) #ovo je prvi frame,koji je prazan, da bi mogao da se pokrene video\n",
    "global cap1\n",
    "show_text=[0]\n",
    "global frame_number\n",
    "\n",
    "# Funkcija koja pokrece video ili video kameru u zavisnosti od toga sta zelimo\n",
    "def show_subject():\n",
    "    global cap1\n",
    "    cap1 = cv2.VideoCapture(r'Klipovi\\Naziv_videa.mp4') #ovdje ubacite video, nadjite kad ucitate koji je tacan path,\n",
    "    #ovo r ispred '' valjda sluzi da \\ procita bukvalno a ne da nesto radi\n",
    "    \n",
    "    #ukoliko zelimo da ucitavamo video sa video kamere\n",
    "    #cap1 = cv2.VideoCapture(0)\n",
    "    \n",
    "    #ukoliko ne ucita ni kameru ni video izbacuje gresku \n",
    "    if not cap1.isOpened():\n",
    "        print(\"cant open the camera\")\n",
    "    \n",
    "    #ovaj dio koda valjda radi da ugasi gui kad se zavrsi snimak, al nisam siguran da meni radi :), moze i bez ovoga \n",
    "    global frame_number\n",
    "    length = int(cap1.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "    frame_number += 1\n",
    "    if frame_number >= length:\n",
    "        exit()\n",
    "    \n",
    "    #ovo je dio koji prepoznaje lice\n",
    "    cap1.set(1, frame_number)    \n",
    "    flag1, frame1 = cap1.read() #ucitava frame\n",
    "    frame1 = cv2.resize(frame1,(400,500)) #### ovaj broj piksela korigujte ako ocete video kameru da otvorite, meni je za kameru 600,500 odgovara\n",
    "    bound_box = cv2.CascadeClassifier('haarcascade_frontalface_default.xml') #ovaj fajl sluzi za to prepoznavanje\n",
    "    gray_frame = cv2.cvtColor(frame1, cv2.COLOR_BGR2GRAY) #ovo pretvara sliku u crno belu, jer smo program trenirali na crno belim slikama\n",
    "    n_faces = bound_box.detectMultiScale(gray_frame,scaleFactor=1.3, minNeighbors=5) #ovo je valjda nesto sto u sustini radi da ne prepoznaje isto lice vise puta\n",
    "\n",
    "    #ovdje crtamo pravougaonik oko lica\n",
    "    #zatim secemo da slika bude 48,48 kao i podaci\n",
    "    #predvidjamo emociju i ispisujemo iznad glave\n",
    "    #i cuvamo redni broj emocije da bismo posle nacrtali odgovarajuci emoji\n",
    "    for (x, y, w, h) in n_faces:\n",
    "        cv2.rectangle(frame1, (x, y-50), (x+w, y+h+10), (255, 0, 0), 2)\n",
    "        roi_frame = gray_frame[y:y + h, x:x + w]\n",
    "        crop_img = np.expand_dims(np.expand_dims(cv2.resize(roi_frame, (48, 48)), -1), 0)\n",
    "        prediction = face_model.predict(crop_img)\n",
    "        maxindex = int(np.argmax(prediction))\n",
    "        cv2.putText(frame1, emotion_dict[maxindex], (x+20, y-60), cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 255, 255), 2, cv2.LINE_AA)\n",
    "        show_text[0]=maxindex\n",
    "    \n",
    "    #flag nam je isto sto i frame, ovdje detektuje da li postoji, i ispisuje gresku ako ne\n",
    "    if flag1 is None:\n",
    "        print (\"Error!\")\n",
    "    \n",
    "    #ovo je dio koda koji prebacuje na sledeci frejm, ne znam tacno zasto je neophodan koji korak, mrzi me da analiziram\n",
    "    \n",
    "    elif flag1:\n",
    "        global last_frame1\n",
    "        last_frame1 = frame1.copy()\n",
    "        pic = cv2.cvtColor(last_frame1, cv2.COLOR_BGR2RGB)\n",
    "        img = Image.fromarray(pic)\n",
    "        imgtk = ImageTk.PhotoImage(image=img)\n",
    "        lmain.imgtk = imgtk\n",
    "        lmain.configure(image=imgtk)\n",
    "        root.update()\n",
    "        lmain.after(1, show_subject)\n",
    "        \n",
    "    #klikom na slovo q se prekida program, mada meni nesto ne radi kako treba nzm\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        exit()\n",
    "\n",
    "#Funckija za prikazivanje emodzija, tu nema nista bitno u kodu, samo estetika \n",
    "def show_avatar():\n",
    "    frame2=cv2.imread(emoji_dist[show_text[0]])\n",
    "    pic2=cv2.cvtColor(frame2,cv2.COLOR_BGR2RGB)\n",
    "    img2=Image.fromarray(pic2)\n",
    "    imgtk2=ImageTk.PhotoImage(image=img2)\n",
    "    lmain2.imgtk2=imgtk2\n",
    "    lmain2.configure(image=imgtk2)\n",
    "    lmain2.after(1, show_avatar)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7d805d4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 276ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n"
     ]
    }
   ],
   "source": [
    "#ovo je glavni dio koda, \n",
    "if __name__ == '__main__':\n",
    "    frame_number = 0\n",
    "    root=tk.Tk() #ovo je taj gui\n",
    "    lmain = tk.Label(master=root,padx=50,bd=10) #ovo je box u kome se nalazi snimak, ili kamera\n",
    "    lmain2 = tk.Label(master=root,bd=10, bg = 'black') #ovo je box u kome se nalazi emoji\n",
    "    #ovo je samo estetika\n",
    "    lmain.pack(side=LEFT)\n",
    "    lmain.place(x=50,y=120)\n",
    "    lmain2.pack(side=RIGHT)\n",
    "    lmain2.place(x=800,y=70)\n",
    "    root.title(\"Emojify\")\n",
    "    root.geometry(\"1400x900+100+10\")\n",
    "    root['bg']='black'\n",
    "    #dugme za prekidanje programa, kada ocete da ugasite klikajte ovo, a ne x na prozoru, jer zablokira kernel\n",
    "    exitbutton = Button(root, text='QUIT',fg=\"red\",command=root.destroy,font=('arial',25,'bold')).pack(side = BOTTOM)\n",
    "    #prikazi video\n",
    "    threading.Thread(target=show_subject).start()\n",
    "    #prikazi emoji\n",
    "    threading.Thread(target=show_avatar).start()\n",
    "    #ponovi\n",
    "    root.mainloop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
