{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dbb21bd5",
   "metadata": {},
   "source": [
    "## Treniranje modela\n",
    "Ucitavamo sve potrebne biblioteke"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4651be0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Flatten\n",
    "from tensorflow.keras.layers import Conv2D\n",
    "from tensorflow.keras.layers import MaxPooling2D\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e34b0c2e",
   "metadata": {},
   "source": [
    "ucitavamo podatke iz foldera data u kome se nalaze fotografije podijeljene i trening i test skup (naravno ako pokrecete naravno vidite koji je tacno path tih foldera) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "52be4299",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 28709 images belonging to 7 classes.\n",
      "Found 7178 images belonging to 7 classes.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "train_dir = 'Data/train'\n",
    "test_dir = 'Data/test'\n",
    "#generisemo dataset od fotografija i stavljamo da vrijednost boje u pikselima bude na skali od 0 do 1, a ne od 0 do 255\n",
    "train_datagenerator = ImageDataGenerator(rescale=1./255)\n",
    "test_datagenerator = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "train_generator = train_datagenerator.flow_from_directory(\n",
    "        train_dir, #putanja\n",
    "        target_size=(48,48),#velicina fotografija\n",
    "        batch_size=64,#broj instanci koje uzimamo prilikom jednog koraka gradijentnog spusta\n",
    "        color_mode=\"grayscale\",\n",
    "        class_mode='categorical') \n",
    "\n",
    "test_generator = test_datagenerator.flow_from_directory(\n",
    "        test_dir,\n",
    "        target_size=(48,48),\n",
    "        batch_size=64,\n",
    "        color_mode=\"grayscale\",\n",
    "        class_mode='categorical')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3259e93c",
   "metadata": {},
   "source": [
    "Pravimo arhitekturu modela, dodajemo sloj po sloj,  o detaljima cemo komentarisati kad zavrsimo uvodi tekst o cnn i fcnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "338b30be",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "recognition_model = Sequential()\n",
    "\n",
    "recognition_model.add(Conv2D(32, kernel_size=(3, 3), activation='relu', input_shape=(48,48,1)))\n",
    "recognition_model.add(Conv2D(64, kernel_size=(3, 3), activation='relu'))\n",
    "recognition_model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "recognition_model.add(Dropout(0.25))\n",
    "\n",
    "recognition_model.add(Conv2D(128, kernel_size=(3, 3), activation='relu'))\n",
    "recognition_model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "recognition_model.add(Conv2D(128, kernel_size=(3, 3), activation='relu'))\n",
    "recognition_model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "recognition_model.add(Dropout(0.25))\n",
    "#fcnn dio arhitekture\n",
    "recognition_model.add(Flatten())\n",
    "recognition_model.add(Dense(1024, activation='relu'))\n",
    "recognition_model.add(Dropout(0.5))\n",
    "recognition_model.add(Dense(7, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "12dc2180",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_8 (Conv2D)           (None, 46, 46, 32)        320       \n",
      "                                                                 \n",
      " conv2d_9 (Conv2D)           (None, 44, 44, 64)        18496     \n",
      "                                                                 \n",
      " max_pooling2d_6 (MaxPoolin  (None, 22, 22, 64)        0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " dropout_6 (Dropout)         (None, 22, 22, 64)        0         \n",
      "                                                                 \n",
      " conv2d_10 (Conv2D)          (None, 20, 20, 128)       73856     \n",
      "                                                                 \n",
      " max_pooling2d_7 (MaxPoolin  (None, 10, 10, 128)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_11 (Conv2D)          (None, 8, 8, 128)         147584    \n",
      "                                                                 \n",
      " max_pooling2d_8 (MaxPoolin  (None, 4, 4, 128)         0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " dropout_7 (Dropout)         (None, 4, 4, 128)         0         \n",
      "                                                                 \n",
      " flatten_2 (Flatten)         (None, 2048)              0         \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 1024)              2098176   \n",
      "                                                                 \n",
      " dropout_8 (Dropout)         (None, 1024)              0         \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 7)                 7175      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2345607 (8.95 MB)\n",
      "Trainable params: 2345607 (8.95 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "recognition_model.summary() "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37088945",
   "metadata": {},
   "source": [
    "Treniramo model, ovaj dio programa radi 5 i po sati."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a230e32f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "recognition_model.compile(loss='categorical_crossentropy',optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.0001, decay=1e-6),metrics=['accuracy'])\n",
    "\n",
    "recognition_model_info = recognition_model.fit_generator(\n",
    "        train_generator, #trening podaci\n",
    "        steps_per_epoch=28709 // 64, \n",
    "        epochs=60,\n",
    "        validation_data=test_generator,#test tj validation podaci \n",
    "        validation_steps=7178 // 64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd39d4aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "#cuvamo weights modela u ovom fajlu, i posle to koristimo, i ne moramo vise da pokrecemo gornji kod\n",
    "recognition_model.save_weights('recogntion_model.h5')\n",
    "#ja sam ih ubacio u folder tako da vi u sustini ne morate da pokrecete, osim ako necete da nacrtate grafik sledeci\n",
    "\n",
    "#ovo je crtanje grafika accuracy na trening i test skupu, meni su se izgubili podaci, pa nemam nacrtano sad\n",
    "plt.title('Model Accuracy')\n",
    "plt.plot(recognition_model_info.history['accuracy'])\n",
    "plt.plot(recognition_model_info.history['val_accuracy'])\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
